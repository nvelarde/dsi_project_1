{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nate_velarde/dsi/dsi_workspace/dsi_project_1\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "\n",
    "## Step 1: Open the `sat_scores.csv` file. Investigate the data, and answer the questions below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. What does the data describe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Does the data look complete? Are there any obvious issues with the observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Create a data dictionary for the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Load the data into a list of lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import csv\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to load in the data is provided below. \n",
    "\n",
    "The `with open(..., 'r') as f:` opens up a file in \"read\" mode (rather than \"write\"), and assigns this opened file to `f`. \n",
    "\n",
    "We then use the `.readlines()` built-in function to split the csv file on newlines and assign it to the variable `lines`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = \"/Users/nate_velarde/dsi/dsi_repo/DSI_SM_3/projects/project-01/assets/sat_scores.csv\"\n",
    "with open(file,'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Print the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['State,Rate,Verbal,Math\\n',\n",
       " 'CT,82,509,510\\n',\n",
       " 'NJ,81,499,513\\n',\n",
       " 'MA,79,511,515\\n',\n",
       " 'NY,77,495,505\\n',\n",
       " 'NH,72,520,516\\n',\n",
       " 'RI,71,501,499\\n',\n",
       " 'PA,71,500,499\\n',\n",
       " 'VT,69,511,506\\n',\n",
       " 'ME,69,506,500\\n',\n",
       " 'VA,68,510,501\\n',\n",
       " 'DE,67,501,499\\n',\n",
       " 'MD,65,508,510\\n',\n",
       " 'NC,65,493,499\\n',\n",
       " 'GA,63,491,489\\n',\n",
       " 'IN,60,499,501\\n',\n",
       " 'SC,57,486,488\\n',\n",
       " 'DC,56,482,474\\n',\n",
       " 'OR,55,526,526\\n',\n",
       " 'FL,54,498,499\\n',\n",
       " 'WA,53,527,527\\n',\n",
       " 'TX,53,493,499\\n',\n",
       " 'HI,52,485,515\\n',\n",
       " 'AK,51,514,510\\n',\n",
       " 'CA,51,498,517\\n',\n",
       " 'AZ,34,523,525\\n',\n",
       " 'NV,33,509,515\\n',\n",
       " 'CO,31,539,542\\n',\n",
       " 'OH,26,534,439\\n',\n",
       " 'MT,23,539,539\\n',\n",
       " 'WV,18,527,512\\n',\n",
       " 'ID,17,543,542\\n',\n",
       " 'TN,13,562,553\\n',\n",
       " 'NM,13,551,542\\n',\n",
       " 'IL,12,576,589\\n',\n",
       " 'KY,12,550,550\\n',\n",
       " 'WY,11,547,545\\n',\n",
       " 'MI,11,561,572\\n',\n",
       " 'MN,9,580,589\\n',\n",
       " 'KS,9,577,580\\n',\n",
       " 'AL,9,559,554\\n',\n",
       " 'NE,8,562,568\\n',\n",
       " 'OK,8,567,561\\n',\n",
       " 'MO,8,577,577\\n',\n",
       " 'LA,7,564,562\\n',\n",
       " 'WI,6,584,596\\n',\n",
       " 'AR,6,562,550\\n',\n",
       " 'UT,5,575,570\\n',\n",
       " 'IA,5,593,603\\n',\n",
       " 'SD,4,577,582\\n',\n",
       " 'ND,4,592,599\\n',\n",
       " 'MS,4,566,551\\n',\n",
       " 'All,45,506,514\\n']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Examining the lines object\n",
    "\n",
    "lines object is a list of strings\n",
    "\n",
    "The header is the first string in the list of strings. It contains the column names of our data.\n",
    "\n",
    "Header row column names: 'State' 'Rate' 'Verbal' 'Math'\n",
    "\n",
    "'Rate' appears to be the percentage of HS students in a state that take the SAT\n",
    "\n",
    "Eyeballing the data suggests that 'Rate' has a wide range (MS: 4 - CT: 82)\n",
    "\n",
    "Subsequent elements contain state name, rate, average verbal score, average math score\n",
    "\n",
    "Final list element is 'All' the states with what looks like national averages for rate, verbal and math\n",
    "\n",
    "There are still '\\n' newline characters that were not removed by .readlines() - will need to clean up\n",
    "\n",
    "From visual inspection of data there appears to be no missing data (empty fields) for any of the states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing the remaining newline `'\\n'` characters with a for-loop\n",
    "\n",
    "for-loop will iterate through the lines of the data and remove the unwanted newline characters.\n",
    "\n",
    "**`.replace('\\n', '')`** is a built-in string function that will take as the first argument the substring you want to replace, and as its second argument the string you want to replace it with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['State,Rate,Verbal,Math',\n",
       " 'CT,82,509,510',\n",
       " 'NJ,81,499,513',\n",
       " 'MA,79,511,515',\n",
       " 'NY,77,495,505',\n",
       " 'NH,72,520,516',\n",
       " 'RI,71,501,499',\n",
       " 'PA,71,500,499',\n",
       " 'VT,69,511,506',\n",
       " 'ME,69,506,500',\n",
       " 'VA,68,510,501',\n",
       " 'DE,67,501,499',\n",
       " 'MD,65,508,510',\n",
       " 'NC,65,493,499',\n",
       " 'GA,63,491,489',\n",
       " 'IN,60,499,501',\n",
       " 'SC,57,486,488',\n",
       " 'DC,56,482,474',\n",
       " 'OR,55,526,526',\n",
       " 'FL,54,498,499',\n",
       " 'WA,53,527,527',\n",
       " 'TX,53,493,499',\n",
       " 'HI,52,485,515',\n",
       " 'AK,51,514,510',\n",
       " 'CA,51,498,517',\n",
       " 'AZ,34,523,525',\n",
       " 'NV,33,509,515',\n",
       " 'CO,31,539,542',\n",
       " 'OH,26,534,439',\n",
       " 'MT,23,539,539',\n",
       " 'WV,18,527,512',\n",
       " 'ID,17,543,542',\n",
       " 'TN,13,562,553',\n",
       " 'NM,13,551,542',\n",
       " 'IL,12,576,589',\n",
       " 'KY,12,550,550',\n",
       " 'WY,11,547,545',\n",
       " 'MI,11,561,572',\n",
       " 'MN,9,580,589',\n",
       " 'KS,9,577,580',\n",
       " 'AL,9,559,554',\n",
       " 'NE,8,562,568',\n",
       " 'OK,8,567,561',\n",
       " 'MO,8,577,577',\n",
       " 'LA,7,564,562',\n",
       " 'WI,6,584,596',\n",
       " 'AR,6,562,550',\n",
       " 'UT,5,575,570',\n",
       " 'IA,5,593,603',\n",
       " 'SD,4,577,582',\n",
       " 'ND,4,592,599',\n",
       " 'MS,4,566,551',\n",
       " 'All,45,506,514']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_lines = []\n",
    "for line in lines:  \n",
    "    cleaned_lines.append(line.replace('\\n',''))\n",
    "cleaned_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 6. Extract a list of the labels from the data, and remove them from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'State,Rate,Verbal,Math'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = cleaned_lines[0]\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CT,82,509,510',\n",
       " 'NJ,81,499,513',\n",
       " 'MA,79,511,515',\n",
       " 'NY,77,495,505',\n",
       " 'NH,72,520,516',\n",
       " 'RI,71,501,499',\n",
       " 'PA,71,500,499',\n",
       " 'VT,69,511,506',\n",
       " 'ME,69,506,500',\n",
       " 'VA,68,510,501',\n",
       " 'DE,67,501,499',\n",
       " 'MD,65,508,510',\n",
       " 'NC,65,493,499',\n",
       " 'GA,63,491,489',\n",
       " 'IN,60,499,501',\n",
       " 'SC,57,486,488',\n",
       " 'DC,56,482,474',\n",
       " 'OR,55,526,526',\n",
       " 'FL,54,498,499',\n",
       " 'WA,53,527,527',\n",
       " 'TX,53,493,499',\n",
       " 'HI,52,485,515',\n",
       " 'AK,51,514,510',\n",
       " 'CA,51,498,517',\n",
       " 'AZ,34,523,525',\n",
       " 'NV,33,509,515',\n",
       " 'CO,31,539,542',\n",
       " 'OH,26,534,439',\n",
       " 'MT,23,539,539',\n",
       " 'WV,18,527,512',\n",
       " 'ID,17,543,542',\n",
       " 'TN,13,562,553',\n",
       " 'NM,13,551,542',\n",
       " 'IL,12,576,589',\n",
       " 'KY,12,550,550',\n",
       " 'WY,11,547,545',\n",
       " 'MI,11,561,572',\n",
       " 'MN,9,580,589',\n",
       " 'KS,9,577,580',\n",
       " 'AL,9,559,554',\n",
       " 'NE,8,562,568',\n",
       " 'OK,8,567,561',\n",
       " 'MO,8,577,577',\n",
       " 'LA,7,564,562',\n",
       " 'WI,6,584,596',\n",
       " 'AR,6,562,550',\n",
       " 'UT,5,575,570',\n",
       " 'IA,5,593,603',\n",
       " 'SD,4,577,582',\n",
       " 'ND,4,592,599',\n",
       " 'MS,4,566,551',\n",
       " 'All,45,506,514']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = cleaned_lines[1:]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Create a list of State names extracted from the data. (Hint: use the list of labels to index on the State column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Split the header and the data strings on commas\n",
    "\n",
    "To split a string on the comma character, will use the **`.split(',')`** built-in function. \n",
    "\n",
    "Split the header on commas first and print it. You can see that the original string is now a list, with items that were originally separated by commas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the header on commas.\n",
    "\n",
    "Go from original string to a list of 4 strings - items that were originally separated by commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['State', 'Rate', 'Verbal', 'Math']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = header.split(',')\n",
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data on commas.\n",
    "\n",
    "Go from 'data' - a list of strings TO a list of a list of strings 'split_data'\n",
    "\n",
    "This is accomplished by iterating through the strings in 'data' and using the .split(',') built-in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_data = []\n",
    "for datum in data:\n",
    "    split_data.append(datum.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CT', '82', '509', '510'],\n",
       " ['NJ', '81', '499', '513'],\n",
       " ['MA', '79', '511', '515'],\n",
       " ['NY', '77', '495', '505'],\n",
       " ['NH', '72', '520', '516'],\n",
       " ['RI', '71', '501', '499'],\n",
       " ['PA', '71', '500', '499'],\n",
       " ['VT', '69', '511', '506'],\n",
       " ['ME', '69', '506', '500'],\n",
       " ['VA', '68', '510', '501'],\n",
       " ['DE', '67', '501', '499'],\n",
       " ['MD', '65', '508', '510'],\n",
       " ['NC', '65', '493', '499'],\n",
       " ['GA', '63', '491', '489'],\n",
       " ['IN', '60', '499', '501'],\n",
       " ['SC', '57', '486', '488'],\n",
       " ['DC', '56', '482', '474'],\n",
       " ['OR', '55', '526', '526'],\n",
       " ['FL', '54', '498', '499'],\n",
       " ['WA', '53', '527', '527'],\n",
       " ['TX', '53', '493', '499'],\n",
       " ['HI', '52', '485', '515'],\n",
       " ['AK', '51', '514', '510'],\n",
       " ['CA', '51', '498', '517'],\n",
       " ['AZ', '34', '523', '525'],\n",
       " ['NV', '33', '509', '515'],\n",
       " ['CO', '31', '539', '542'],\n",
       " ['OH', '26', '534', '439'],\n",
       " ['MT', '23', '539', '539'],\n",
       " ['WV', '18', '527', '512'],\n",
       " ['ID', '17', '543', '542'],\n",
       " ['TN', '13', '562', '553'],\n",
       " ['NM', '13', '551', '542'],\n",
       " ['IL', '12', '576', '589'],\n",
       " ['KY', '12', '550', '550'],\n",
       " ['WY', '11', '547', '545'],\n",
       " ['MI', '11', '561', '572'],\n",
       " ['MN', '9', '580', '589'],\n",
       " ['KS', '9', '577', '580'],\n",
       " ['AL', '9', '559', '554'],\n",
       " ['NE', '8', '562', '568'],\n",
       " ['OK', '8', '567', '561'],\n",
       " ['MO', '8', '577', '577'],\n",
       " ['LA', '7', '564', '562'],\n",
       " ['WI', '6', '584', '596'],\n",
       " ['AR', '6', '562', '550'],\n",
       " ['UT', '5', '575', '570'],\n",
       " ['IA', '5', '593', '603'],\n",
       " ['SD', '4', '577', '582'],\n",
       " ['ND', '4', '592', '599'],\n",
       " ['MS', '4', '566', '551'],\n",
       " ['All', '45', '506', '514']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a list of state names\n",
    "\n",
    "Selecting an individual state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CT'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a list of states, need to iterate through each individual list ('row') in 'split_data'\n",
    "and select the first element of that list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_names = []\n",
    "for row in split_data:\n",
    "    state_names.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT', 'NJ', 'MA', 'NY', 'NH', 'RI', 'PA', 'VT', 'ME', 'VA', 'DE', 'MD', 'NC', 'GA', 'IN', 'SC', 'DC', 'OR', 'FL', 'WA', 'TX', 'HI', 'AK', 'CA', 'AZ', 'NV', 'CO', 'OH', 'MT', 'WV', 'ID', 'TN', 'NM', 'IL', 'KY', 'WY', 'MI', 'MN', 'KS', 'AL', 'NE', 'OK', 'MO', 'LA', 'WI', 'AR', 'UT', 'IA', 'SD', 'ND', 'MS', 'All']\n"
     ]
    }
   ],
   "source": [
    "print state_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(state_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Print the types of each column\n",
    "\n",
    "Did this problem both ways - looked at the data type of the columns (lists) as a whole as well as the type of each\n",
    "individual element of those lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State column type:  <type 'list'>\n",
      "Rate column type:  <type 'list'>\n",
      "Verbal column type:  <type 'list'>\n",
      "Math column type:  <type 'list'>\n"
     ]
    }
   ],
   "source": [
    "for index, element in enumerate(header):\n",
    "    \n",
    "    split_data_columns = []\n",
    "    for row in split_data:\n",
    "        split_data_columns.append(row[index])\n",
    "    \n",
    "    print element + \" column type: \", type(split_data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str],\n",
       " [str, str, str, str]]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data_types = []\n",
    "\n",
    "for row in split_data:\n",
    "    \n",
    "    new_row = []\n",
    "    \n",
    "    for index, element in enumerate(row):\n",
    "        data_type = type(element)\n",
    "        new_row.append(data_type)\n",
    "    \n",
    "    split_data_types.append(new_row)\n",
    "    \n",
    "split_data_types\n",
    "\n",
    "# All of the data in the data set are strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Do any types need to be reassigned? If so, go ahead and do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Need to clean up the data to convert string numbers to float numbers so we can do calculations later\n",
    "\n",
    "Keeping first column as strings they are state names (abbreviations)\n",
    "\n",
    "Not necessary for the data set based on visual inspection, but then check for empty fields\n",
    "and if any are found, set them to 'None'\n",
    "\n",
    "Convert 'string numbers' to floats so we can do calculations later\n",
    "\n",
    "Remove the summary 'All' (last row) as its value may skew calculations and graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CT', 82.0, 509.0, 510.0],\n",
       " ['NJ', 81.0, 499.0, 513.0],\n",
       " ['MA', 79.0, 511.0, 515.0],\n",
       " ['NY', 77.0, 495.0, 505.0],\n",
       " ['NH', 72.0, 520.0, 516.0],\n",
       " ['RI', 71.0, 501.0, 499.0],\n",
       " ['PA', 71.0, 500.0, 499.0],\n",
       " ['VT', 69.0, 511.0, 506.0],\n",
       " ['ME', 69.0, 506.0, 500.0],\n",
       " ['VA', 68.0, 510.0, 501.0],\n",
       " ['DE', 67.0, 501.0, 499.0],\n",
       " ['MD', 65.0, 508.0, 510.0],\n",
       " ['NC', 65.0, 493.0, 499.0],\n",
       " ['GA', 63.0, 491.0, 489.0],\n",
       " ['IN', 60.0, 499.0, 501.0],\n",
       " ['SC', 57.0, 486.0, 488.0],\n",
       " ['DC', 56.0, 482.0, 474.0],\n",
       " ['OR', 55.0, 526.0, 526.0],\n",
       " ['FL', 54.0, 498.0, 499.0],\n",
       " ['WA', 53.0, 527.0, 527.0],\n",
       " ['TX', 53.0, 493.0, 499.0],\n",
       " ['HI', 52.0, 485.0, 515.0],\n",
       " ['AK', 51.0, 514.0, 510.0],\n",
       " ['CA', 51.0, 498.0, 517.0],\n",
       " ['AZ', 34.0, 523.0, 525.0],\n",
       " ['NV', 33.0, 509.0, 515.0],\n",
       " ['CO', 31.0, 539.0, 542.0],\n",
       " ['OH', 26.0, 534.0, 439.0],\n",
       " ['MT', 23.0, 539.0, 539.0],\n",
       " ['WV', 18.0, 527.0, 512.0],\n",
       " ['ID', 17.0, 543.0, 542.0],\n",
       " ['TN', 13.0, 562.0, 553.0],\n",
       " ['NM', 13.0, 551.0, 542.0],\n",
       " ['IL', 12.0, 576.0, 589.0],\n",
       " ['KY', 12.0, 550.0, 550.0],\n",
       " ['WY', 11.0, 547.0, 545.0],\n",
       " ['MI', 11.0, 561.0, 572.0],\n",
       " ['MN', 9.0, 580.0, 589.0],\n",
       " ['KS', 9.0, 577.0, 580.0],\n",
       " ['AL', 9.0, 559.0, 554.0],\n",
       " ['NE', 8.0, 562.0, 568.0],\n",
       " ['OK', 8.0, 567.0, 561.0],\n",
       " ['MO', 8.0, 577.0, 577.0],\n",
       " ['LA', 7.0, 564.0, 562.0],\n",
       " ['WI', 6.0, 584.0, 596.0],\n",
       " ['AR', 6.0, 562.0, 550.0],\n",
       " ['UT', 5.0, 575.0, 570.0],\n",
       " ['IA', 5.0, 593.0, 603.0],\n",
       " ['SD', 4.0, 577.0, 582.0],\n",
       " ['ND', 4.0, 592.0, 599.0],\n",
       " ['MS', 4.0, 566.0, 551.0],\n",
       " ['All', 45.0, 506.0, 514.0]]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data_num = []\n",
    "for row in split_data:\n",
    "    new_row = []\n",
    "    for index, element in enumerate(row):\n",
    "        if index == 0:\n",
    "            new_row.append(element)\n",
    "        else:\n",
    "            if element == '':\n",
    "                new_row.append(None)\n",
    "            else:\n",
    "                new_row.append(float(element))\n",
    "    split_data_num.append(new_row)\n",
    "    \n",
    "split_data_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing the last row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CT', 82.0, 509.0, 510.0],\n",
       " ['NJ', 81.0, 499.0, 513.0],\n",
       " ['MA', 79.0, 511.0, 515.0],\n",
       " ['NY', 77.0, 495.0, 505.0],\n",
       " ['NH', 72.0, 520.0, 516.0],\n",
       " ['RI', 71.0, 501.0, 499.0],\n",
       " ['PA', 71.0, 500.0, 499.0],\n",
       " ['VT', 69.0, 511.0, 506.0],\n",
       " ['ME', 69.0, 506.0, 500.0],\n",
       " ['VA', 68.0, 510.0, 501.0],\n",
       " ['DE', 67.0, 501.0, 499.0],\n",
       " ['MD', 65.0, 508.0, 510.0],\n",
       " ['NC', 65.0, 493.0, 499.0],\n",
       " ['GA', 63.0, 491.0, 489.0],\n",
       " ['IN', 60.0, 499.0, 501.0],\n",
       " ['SC', 57.0, 486.0, 488.0],\n",
       " ['DC', 56.0, 482.0, 474.0],\n",
       " ['OR', 55.0, 526.0, 526.0],\n",
       " ['FL', 54.0, 498.0, 499.0],\n",
       " ['WA', 53.0, 527.0, 527.0],\n",
       " ['TX', 53.0, 493.0, 499.0],\n",
       " ['HI', 52.0, 485.0, 515.0],\n",
       " ['AK', 51.0, 514.0, 510.0],\n",
       " ['CA', 51.0, 498.0, 517.0],\n",
       " ['AZ', 34.0, 523.0, 525.0],\n",
       " ['NV', 33.0, 509.0, 515.0],\n",
       " ['CO', 31.0, 539.0, 542.0],\n",
       " ['OH', 26.0, 534.0, 439.0],\n",
       " ['MT', 23.0, 539.0, 539.0],\n",
       " ['WV', 18.0, 527.0, 512.0],\n",
       " ['ID', 17.0, 543.0, 542.0],\n",
       " ['TN', 13.0, 562.0, 553.0],\n",
       " ['NM', 13.0, 551.0, 542.0],\n",
       " ['IL', 12.0, 576.0, 589.0],\n",
       " ['KY', 12.0, 550.0, 550.0],\n",
       " ['WY', 11.0, 547.0, 545.0],\n",
       " ['MI', 11.0, 561.0, 572.0],\n",
       " ['MN', 9.0, 580.0, 589.0],\n",
       " ['KS', 9.0, 577.0, 580.0],\n",
       " ['AL', 9.0, 559.0, 554.0],\n",
       " ['NE', 8.0, 562.0, 568.0],\n",
       " ['OK', 8.0, 567.0, 561.0],\n",
       " ['MO', 8.0, 577.0, 577.0],\n",
       " ['LA', 7.0, 564.0, 562.0],\n",
       " ['WI', 6.0, 584.0, 596.0],\n",
       " ['AR', 6.0, 562.0, 550.0],\n",
       " ['UT', 5.0, 575.0, 570.0],\n",
       " ['IA', 5.0, 593.0, 603.0],\n",
       " ['SD', 4.0, 577.0, 582.0],\n",
       " ['ND', 4.0, 592.0, 599.0],\n",
       " ['MS', 4.0, 566.0, 551.0]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data_num = split_data_num[0:-1]\n",
    "split_data_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. Create a dictionary for each column mapping the State to its respective value for that column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WA': [53.0, 527.0, 527.0], 'DE': [67.0, 501.0, 499.0], 'DC': [56.0, 482.0, 474.0], 'WI': [6.0, 584.0, 596.0], 'WV': [18.0, 527.0, 512.0], 'HI': [52.0, 485.0, 515.0], 'FL': [54.0, 498.0, 499.0], 'WY': [11.0, 547.0, 545.0], 'NH': [72.0, 520.0, 516.0], 'NJ': [81.0, 499.0, 513.0], 'NM': [13.0, 551.0, 542.0], 'TX': [53.0, 493.0, 499.0], 'LA': [7.0, 564.0, 562.0], 'NC': [65.0, 493.0, 499.0], 'ND': [4.0, 592.0, 599.0], 'NE': [8.0, 562.0, 568.0], 'TN': [13.0, 562.0, 553.0], 'NY': [77.0, 495.0, 505.0], 'PA': [71.0, 500.0, 499.0], 'RI': [71.0, 501.0, 499.0], 'NV': [33.0, 509.0, 515.0], 'VA': [68.0, 510.0, 501.0], 'CO': [31.0, 539.0, 542.0], 'AK': [51.0, 514.0, 510.0], 'AL': [9.0, 559.0, 554.0], 'AR': [6.0, 562.0, 550.0], 'VT': [69.0, 511.0, 506.0], 'IL': [12.0, 576.0, 589.0], 'GA': [63.0, 491.0, 489.0], 'IN': [60.0, 499.0, 501.0], 'IA': [5.0, 593.0, 603.0], 'OK': [8.0, 567.0, 561.0], 'AZ': [34.0, 523.0, 525.0], 'CA': [51.0, 498.0, 517.0], 'ID': [17.0, 543.0, 542.0], 'CT': [82.0, 509.0, 510.0], 'ME': [69.0, 506.0, 500.0], 'MD': [65.0, 508.0, 510.0], 'MA': [79.0, 511.0, 515.0], 'OH': [26.0, 534.0, 439.0], 'UT': [5.0, 575.0, 570.0], 'MO': [8.0, 577.0, 577.0], 'MN': [9.0, 580.0, 589.0], 'MI': [11.0, 561.0, 572.0], 'KS': [9.0, 577.0, 580.0], 'MT': [23.0, 539.0, 539.0], 'MS': [4.0, 566.0, 551.0], 'SC': [57.0, 486.0, 488.0], 'KY': [12.0, 550.0, 550.0], 'OR': [55.0, 526.0, 526.0], 'SD': [4.0, 577.0, 582.0]}\n"
     ]
    }
   ],
   "source": [
    "state_dictionary = {}\n",
    "\n",
    "for row in split_data_num:\n",
    "    state_data_points = []\n",
    "    for index, element in enumerate(row):\n",
    "        if index != 0:\n",
    "            state_data_points.append(element)\n",
    "            \n",
    "    state_dictionary[row[0]] = state_data_points\n",
    "    \n",
    "print state_dictionary\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. Create a dictionary with the values for each of the numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rate': [82.0, 81.0, 79.0, 77.0, 72.0, 71.0, 71.0, 69.0, 69.0, 68.0, 67.0, 65.0, 65.0, 63.0, 60.0, 57.0, 56.0, 55.0, 54.0, 53.0, 53.0, 52.0, 51.0, 51.0, 34.0, 33.0, 31.0, 26.0, 23.0, 18.0, 17.0, 13.0, 13.0, 12.0, 12.0, 11.0, 11.0, 9.0, 9.0, 9.0, 8.0, 8.0, 8.0, 7.0, 6.0, 6.0, 5.0, 5.0, 4.0, 4.0, 4.0, 45.0], 'Math': [510.0, 513.0, 515.0, 505.0, 516.0, 499.0, 499.0, 506.0, 500.0, 501.0, 499.0, 510.0, 499.0, 489.0, 501.0, 488.0, 474.0, 526.0, 499.0, 527.0, 499.0, 515.0, 510.0, 517.0, 525.0, 515.0, 542.0, 439.0, 539.0, 512.0, 542.0, 553.0, 542.0, 589.0, 550.0, 545.0, 572.0, 589.0, 580.0, 554.0, 568.0, 561.0, 577.0, 562.0, 596.0, 550.0, 570.0, 603.0, 582.0, 599.0, 551.0, 514.0], 'Verbal': [509.0, 499.0, 511.0, 495.0, 520.0, 501.0, 500.0, 511.0, 506.0, 510.0, 501.0, 508.0, 493.0, 491.0, 499.0, 486.0, 482.0, 526.0, 498.0, 527.0, 493.0, 485.0, 514.0, 498.0, 523.0, 509.0, 539.0, 534.0, 539.0, 527.0, 543.0, 562.0, 551.0, 576.0, 550.0, 547.0, 561.0, 580.0, 577.0, 559.0, 562.0, 567.0, 577.0, 564.0, 584.0, 562.0, 575.0, 593.0, 577.0, 592.0, 566.0, 506.0]}\n"
     ]
    }
   ],
   "source": [
    "column_dictionary = {}\n",
    "col_index = 0\n",
    "\n",
    "for head in header[1:]:\n",
    "    col_index += 1\n",
    "    column_list = []\n",
    "    \n",
    "    for row in split_data_num:\n",
    "\n",
    "        column_list.append(row[col_index])\n",
    "        column_dictionary[head] = column_list\n",
    "\n",
    "print column_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Describe the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Print the min and max of each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Printing the maximum of each numeric column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate Column Maximum Value:  82.0\n",
      "Verbal Column Maximum Value:  593.0\n",
      "Math Column Maximum Value:  603.0\n"
     ]
    }
   ],
   "source": [
    "for head in header[1:]:\n",
    "    column_max_value = max(column_dictionary.get(head))\n",
    "    print head + \" Column Maximum Value: \", column_max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Printing the minimum of each numeric column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate Column Minimum Value:  4.0\n",
      "Verbal Column Minimum Value:  482.0\n",
      "Math Column Minimum Value:  439.0\n"
     ]
    }
   ],
   "source": [
    "for head in header[1:]:\n",
    "    column_min_value = min(column_dictionary.get(head))\n",
    "    print head + \" Column Minimum Value: \", column_min_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 13. Write a function using only list comprehensions, no loops, to compute Standard Deviation. Print the Standard Deviation of each numeric column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Writing a function to compute the standard deviation of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number 13: INDIVIDUAL COMPONENT CODE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82.0, 81.0, 79.0, 77.0, 72.0, 71.0, 71.0, 69.0, 69.0, 68.0, 67.0, 65.0, 65.0, 63.0, 60.0, 57.0, 56.0, 55.0, 54.0, 53.0, 53.0, 52.0, 51.0, 51.0, 34.0, 33.0, 31.0, 26.0, 23.0, 18.0, 17.0, 13.0, 13.0, 12.0, 12.0, 11.0, 11.0, 9.0, 9.0, 9.0, 8.0, 8.0, 8.0, 7.0, 6.0, 6.0, 5.0, 5.0, 4.0, 4.0, 4.0, 45.0]\n"
     ]
    }
   ],
   "source": [
    "column_values = column_dictionary.get('Rate')\n",
    "print column_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.15384615384615"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_mean = sum(column_values)/len(column_values)\n",
    "column_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2011.1775147928995,\n",
       " 1922.4852071005917,\n",
       " 1751.1005917159764,\n",
       " 1587.715976331361,\n",
       " 1214.2544378698226,\n",
       " 1145.5621301775147,\n",
       " 1145.5621301775147,\n",
       " 1014.1775147928994,\n",
       " 1014.1775147928994,\n",
       " 951.4852071005918,\n",
       " 890.792899408284,\n",
       " 775.4082840236687,\n",
       " 775.4082840236687,\n",
       " 668.0236686390533,\n",
       " 521.9467455621302,\n",
       " 393.8698224852071,\n",
       " 355.17751479289944,\n",
       " 318.4852071005917,\n",
       " 283.79289940828403,\n",
       " 251.10059171597635,\n",
       " 251.10059171597635,\n",
       " 220.40828402366864,\n",
       " 191.71597633136096,\n",
       " 191.71597633136096,\n",
       " 9.946745562130173,\n",
       " 17.254437869822482,\n",
       " 37.869822485207095,\n",
       " 124.40828402366863,\n",
       " 200.33136094674555,\n",
       " 366.86982248520707,\n",
       " 406.1775147928994,\n",
       " 583.4082840236686,\n",
       " 583.4082840236686,\n",
       " 632.7159763313609,\n",
       " 632.7159763313609,\n",
       " 684.0236686390532,\n",
       " 684.0236686390532,\n",
       " 792.6390532544378,\n",
       " 792.6390532544378,\n",
       " 792.6390532544378,\n",
       " 849.9467455621301,\n",
       " 849.9467455621301,\n",
       " 849.9467455621301,\n",
       " 909.2544378698225,\n",
       " 970.5621301775147,\n",
       " 970.5621301775147,\n",
       " 1033.8698224852071,\n",
       " 1033.8698224852071,\n",
       " 1099.1775147928993,\n",
       " 1099.1775147928993,\n",
       " 1099.1775147928993,\n",
       " 61.5621301775148]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_variances = [(i - column_mean) ** 2 for i in column_values]\n",
    "column_variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731.05325443787"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_variance = sum(column_variances)/len(column_variances)\n",
    "column_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38014.76923076924"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(column_variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(column_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.03799649452359"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_stdev = column_variance**(0.5)\n",
    "column_stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate Column Differences Squared:  [2011.1775147928995, 1922.4852071005917, 1751.1005917159764, 1587.715976331361, 1214.2544378698226, 1145.5621301775147, 1145.5621301775147, 1014.1775147928994, 1014.1775147928994, 951.4852071005918, 890.792899408284, 775.4082840236687, 775.4082840236687, 668.0236686390533, 521.9467455621302, 393.8698224852071, 355.17751479289944, 318.4852071005917, 283.79289940828403, 251.10059171597635, 251.10059171597635, 220.40828402366864, 191.71597633136096, 191.71597633136096, 9.946745562130173, 17.254437869822482, 37.869822485207095, 124.40828402366863, 200.33136094674555, 366.86982248520707, 406.1775147928994, 583.4082840236686, 583.4082840236686, 632.7159763313609, 632.7159763313609, 684.0236686390532, 684.0236686390532, 792.6390532544378, 792.6390532544378, 792.6390532544378, 849.9467455621301, 849.9467455621301, 849.9467455621301, 909.2544378698225, 970.5621301775147, 970.5621301775147, 1033.8698224852071, 1033.8698224852071, 1099.1775147928993, 1099.1775147928993, 1099.1775147928993, 61.5621301775148]\n",
      "Rate Column Count:  52\n",
      "Rate Column Mean:  37.1538461538\n",
      "Rate Column Standard Deviation:  27.0379964945\n",
      "\n",
      "Verbal Column Differences Squared:  [529.8849852070982, 1090.2696005917126, 441.8080621301753, 1370.4234467455583, 144.4619082840224, 962.1926775147897, 1025.2311390532511, 441.8080621301753, 677.0003698224825, 484.84652366863673, 962.1926775147897, 576.9234467455597, 1522.5003698224812, 1682.577292899404, 1090.2696005917126, 2117.769600591711, 2501.9234467455567, 36.231139053253806, 1157.308062130174, 25.192677514792372, 1522.5003698224812, 2210.8080621301724, 324.692677514791, 1157.308062130174, 81.34652366863811, 529.8849852070982, 48.73113905325517, 3.923446745562338, 48.73113905325517, 25.192677514792372, 120.57729289940944, 898.8465236686422, 360.26960059171796, 1934.3080621301822, 323.3080621301794, 224.4234467455637, 839.8849852071037, 2302.154215976336, 2023.2696005917207, 727.9619082840265, 898.8465236686422, 1223.654215976335, 2023.2696005917207, 1022.7696005917194, 2702.0003698224905, 898.8465236686422, 1847.3465236686436, 3718.6542159763376, 2023.2696005917207, 3597.692677514799, 1154.6926775147965, 677.0003698224825]\n",
      "Verbal Column Count:  52\n",
      "Verbal Column Mean:  532.019230769\n",
      "Verbal Column Standard Deviation:  32.9150949616\n",
      "\n",
      "Math Column Differences Squared:  [462.25, 342.25, 272.25, 702.25, 240.25, 1056.25, 1056.25, 650.25, 992.25, 930.25, 1056.25, 462.25, 1056.25, 1806.25, 930.25, 1892.25, 3306.25, 30.25, 1056.25, 20.25, 1056.25, 272.25, 462.25, 210.25, 42.25, 272.25, 110.25, 8556.25, 56.25, 380.25, 110.25, 462.25, 110.25, 3306.25, 342.25, 182.25, 1640.25, 3306.25, 2352.25, 506.25, 1332.25, 870.25, 2070.25, 930.25, 4160.25, 342.25, 1482.25, 5112.25, 2550.25, 4556.25, 380.25, 306.25]\n",
      "Math Column Count:  52\n",
      "Math Column Mean:  531.5\n",
      "Math Column Standard Deviation:  35.6669961643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for head in header[1:]:\n",
    "    column_values = []\n",
    "    column_values = column_dictionary.get(head)\n",
    "    column_mean = sum(column_values)/len(column_values)\n",
    "    column_diffs_sqd = [(i - column_mean) ** 2 for i in column_values]\n",
    "    column_variance = sum(column_diffs_sqd) / len(column_diffs_sqd)\n",
    "    column_stdev = column_variance ** (0.5)\n",
    "    \n",
    "    print head + \" Column Differences Squared: \", column_diffs_sqd\n",
    "    print head + \" Column Count: \", len(column_diffs_sqd)\n",
    "    print head + \" Column Mean: \", column_mean\n",
    "    print head + \" Column Standard Deviation: \", column_stdev\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82.0, 82.0, 82.0, 82.0, 81.0, 81.0, 81.0, 81.0, 79.0, 79.0, 79.0, 79.0, 77.0, 77.0, 77.0, 77.0, 72.0, 72.0, 72.0, 72.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 68.0, 68.0, 68.0, 68.0, 67.0, 67.0, 67.0, 67.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 63.0, 63.0, 63.0, 63.0, 60.0, 60.0, 60.0, 60.0, 57.0, 57.0, 57.0, 57.0, 56.0, 56.0, 56.0, 56.0, 55.0, 55.0, 55.0, 55.0, 54.0, 54.0, 54.0, 54.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 52.0, 52.0, 52.0, 52.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 34.0, 34.0, 34.0, 34.0, 33.0, 33.0, 33.0, 33.0, 31.0, 31.0, 31.0, 31.0, 26.0, 26.0, 26.0, 26.0, 23.0, 23.0, 23.0, 23.0, 18.0, 18.0, 18.0, 18.0, 17.0, 17.0, 17.0, 17.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 45.0, 45.0, 45.0, 45.0]\n"
     ]
    }
   ],
   "source": [
    "column_values = column_dictionary.get('Rate')\n",
    "print column_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[510.0, 510.0, 510.0, 510.0, 513.0, 513.0, 513.0, 513.0, 515.0, 515.0, 515.0, 515.0, 505.0, 505.0, 505.0, 505.0, 516.0, 516.0, 516.0, 516.0, 499.0, 499.0, 499.0, 499.0, 499.0, 499.0, 499.0, 499.0, 506.0, 506.0, 506.0, 506.0, 500.0, 500.0, 500.0, 500.0, 501.0, 501.0, 501.0, 501.0, 499.0, 499.0, 499.0, 499.0, 510.0, 510.0, 510.0, 510.0, 499.0, 499.0, 499.0, 499.0, 489.0, 489.0, 489.0, 489.0, 501.0, 501.0, 501.0, 501.0, 488.0, 488.0, 488.0, 488.0, 474.0, 474.0, 474.0, 474.0, 526.0, 526.0, 526.0, 526.0, 499.0, 499.0, 499.0, 499.0, 527.0, 527.0, 527.0, 527.0, 499.0, 499.0, 499.0, 499.0, 515.0, 515.0, 515.0, 515.0, 510.0, 510.0, 510.0, 510.0, 517.0, 517.0, 517.0, 517.0, 525.0, 525.0, 525.0, 525.0, 515.0, 515.0, 515.0, 515.0, 542.0, 542.0, 542.0, 542.0, 439.0, 439.0, 439.0, 439.0, 539.0, 539.0, 539.0, 539.0, 512.0, 512.0, 512.0, 512.0, 542.0, 542.0, 542.0, 542.0, 553.0, 553.0, 553.0, 553.0, 542.0, 542.0, 542.0, 542.0, 589.0, 589.0, 589.0, 589.0, 550.0, 550.0, 550.0, 550.0, 545.0, 545.0, 545.0, 545.0, 572.0, 572.0, 572.0, 572.0, 589.0, 589.0, 589.0, 589.0, 580.0, 580.0, 580.0, 580.0, 554.0, 554.0, 554.0, 554.0, 568.0, 568.0, 568.0, 568.0, 561.0, 561.0, 561.0, 561.0, 577.0, 577.0, 577.0, 577.0, 562.0, 562.0, 562.0, 562.0, 596.0, 596.0, 596.0, 596.0, 550.0, 550.0, 550.0, 550.0, 570.0, 570.0, 570.0, 570.0, 603.0, 603.0, 603.0, 603.0, 582.0, 582.0, 582.0, 582.0, 599.0, 599.0, 599.0, 599.0, 551.0, 551.0, 551.0, 551.0, 514.0, 514.0, 514.0, 514.0]\n"
     ]
    }
   ],
   "source": [
    "column_values = column_dictionary.get('Math')\n",
    "print column_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[509.0, 509.0, 509.0, 509.0, 499.0, 499.0, 499.0, 499.0, 511.0, 511.0, 511.0, 511.0, 495.0, 495.0, 495.0, 495.0, 520.0, 520.0, 520.0, 520.0, 501.0, 501.0, 501.0, 501.0, 500.0, 500.0, 500.0, 500.0, 511.0, 511.0, 511.0, 511.0, 506.0, 506.0, 506.0, 506.0, 510.0, 510.0, 510.0, 510.0, 501.0, 501.0, 501.0, 501.0, 508.0, 508.0, 508.0, 508.0, 493.0, 493.0, 493.0, 493.0, 491.0, 491.0, 491.0, 491.0, 499.0, 499.0, 499.0, 499.0, 486.0, 486.0, 486.0, 486.0, 482.0, 482.0, 482.0, 482.0, 526.0, 526.0, 526.0, 526.0, 498.0, 498.0, 498.0, 498.0, 527.0, 527.0, 527.0, 527.0, 493.0, 493.0, 493.0, 493.0, 485.0, 485.0, 485.0, 485.0, 514.0, 514.0, 514.0, 514.0, 498.0, 498.0, 498.0, 498.0, 523.0, 523.0, 523.0, 523.0, 509.0, 509.0, 509.0, 509.0, 539.0, 539.0, 539.0, 539.0, 534.0, 534.0, 534.0, 534.0, 539.0, 539.0, 539.0, 539.0, 527.0, 527.0, 527.0, 527.0, 543.0, 543.0, 543.0, 543.0, 562.0, 562.0, 562.0, 562.0, 551.0, 551.0, 551.0, 551.0, 576.0, 576.0, 576.0, 576.0, 550.0, 550.0, 550.0, 550.0, 547.0, 547.0, 547.0, 547.0, 561.0, 561.0, 561.0, 561.0, 580.0, 580.0, 580.0, 580.0, 577.0, 577.0, 577.0, 577.0, 559.0, 559.0, 559.0, 559.0, 562.0, 562.0, 562.0, 562.0, 567.0, 567.0, 567.0, 567.0, 577.0, 577.0, 577.0, 577.0, 564.0, 564.0, 564.0, 564.0, 584.0, 584.0, 584.0, 584.0, 562.0, 562.0, 562.0, 562.0, 575.0, 575.0, 575.0, 575.0, 593.0, 593.0, 593.0, 593.0, 577.0, 577.0, 577.0, 577.0, 592.0, 592.0, 592.0, 592.0, 566.0, 566.0, 566.0, 566.0, 506.0, 506.0, 506.0, 506.0]\n"
     ]
    }
   ],
   "source": [
    "column_values = column_dictionary.get('Verbal')\n",
    "print column_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### 14. Using MatPlotLib and PyPlot, plot the distribution of the Rate using histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Plot the Math distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16. Plot the Verbal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 17. What is the typical assumption for data distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. Does that distribution hold true for our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. Plot some scatterplots. **BONUS**: Use a PyPlot `figure` to present multiple plots at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 20. Are there any interesting relationships to note?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. Create box plots for each variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BONUS: Using Tableau, create a heat map for each variable using a map of the US. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
